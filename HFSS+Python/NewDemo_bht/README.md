# 代理模型辅助优化DEMO

### 写在前面
之前是从 cyang58 学长手搓（其实它应该是直接扒的sko.PSO）的PSO作为demo开始学习HFSS和python的联合仿真优化的。
事实上，学长这个PSO槽点很多，当然也有可能我没能理解它的高深思想。
cyang58 的问题出现在语法琐碎，没能将优化器与评估器好地封装开，以及很滑稽的去追求面向对象。
但是，这是一个三年前的demo式的作品，也不必苛责。
cyang58 的库就是比较完整的，而且提供了自动化的许多例子。

个人而言，我**不建议完整整理完hfss自动化需要的所有功能**，因为这是多余的，我们大可通过 cyang58 的例子，以及hfss的录脚本功能完成自己的需要。
目前而言，**不建议追求一个完善的面向对象效果**，只要实现算法和自动化功能、并且有可读性就行，以免出现一些滑稽的操作。当然，这是我自己的主观想法。
就是说，自己对于文件处理、交互显示之类的事情，在不影响代码可读性的前提下，大可自由一点。
同时，**不建议完全用脚本建模**。在熟悉自动化流程之后，大可以在软件上建模，代码只用来调整变量，或者做小改动以贴合你的场景。
（如果写脚本更方便，那人家做软件出来干啥？）

python是最最最简单的语言，基本上没有语法，事实上，学习入门python并不难。
入门python之后，**尽可能用开源**的东西，一是使你的代码可读性更高，二是你不知道那年再看到自己写的东西，会觉得不堪入目，
又或者，三四年后被过河拆桥的没良心学弟取笑。
但是，所有开源的、别人的东西都可能有错，没有什么代码是天条、是圣旨，不需要迷信什么，也不能简单的评判这个“没用”或者“用不了”。

### 介绍
结合这几个月的经验，我决定重写一个自动化demo，另外附上自己在python上复现可以作为实验对照组的两种简单的*代理模型辅助优化算法*。
它们是并行贝叶斯优化（PBO）以及代理模型辅助差分演化（SADEA）。
以及陆老师提到的傻瓜版CMAES。
在HFSS自带的Optimetrics 中，基本上是一些直接方法和GA。
在对于高维度下的优化时，它们基本上没有任何效果，
这时，机器学习搭建下的辅助模型的引入尤为重要，就有了简单的 **贝叶斯算法BO** （自己百度），以及各种各样的 “模型-搜索引擎-预筛选方法” 排列组合。
在天线设计这个领域，著名水王Bo Liu经典的 **SADEA** 常被拿来讨论。
它是一个比较老（2014）而且朴素（它的排列组合是“高斯过程-差分演化-LCB最优”）的算法，可以被用作一个合适的对照组凸显宁的成果。

### 引用
Optimetrics介绍：[https://blog.csdn.net/qq_41542947/article/details/108104890](http://)

Antenna Toolbox库介绍：[https://ww2.mathworks.cn/products/antenna.html?s_eid=PEP_15027](http://)

PBO天线例子论文：Bayesian Optimization for Antenna Design via Multi-Point Active Learning 

PBO数学方法论文：Pseudo expected improvement criterion for parallel EGO algorithm

SADEA 论文：An Effificient Method for Antenna Design Optimization Based on Evolutionary Computation and Machine Learning Techniques


### 注意事项

言归正传，这只是一个简单的Readme，不是写论文，接下来我就只是简单介绍具体的改动和代码结构大概如何。
1. 首先要解释的是模型的搭建方面。我个人认为有必要在一开始熟悉脚本的时候自己用脚本搭建一两个天线模型。但是事实上脚本搭建的效率远低于手动搭建，而且有的结构脚本并没被录入HFSS.py中，要自己录下再调用，这是明显的不必要的做法。
所以我将各个算法函数的调用都移到了该算法.py的主函数上。只是另保留一个搭建demo所需的DRA模型的Example_a_cylinder_DRA.py。只用运行一下 **生成模型就完了** 。
2. 那么我就在costfunction函数前后加上hfss工程的打开和关闭代码，每次需要仿真时打开HFSS。血泪教训，如果一直打开着HFSS运行会造成严重卡顿，以及生成一堆结果文件挤占空间。
注意，在运行costfunction函数前，不能打开hfss（会被警告重复打开）。

3. 原先PSO中带入costfunction参数里面一堆文件路径，这非常没必要，只用在cf里自己设置就好。同时，学习python本身sko库以及很多优化库里函数的做法，把costfunction也作为PSO形参导入。这样更换costfunction时只需更换它的参数而不用做内部调整。
4. cyang58 的costfunction的计算语法可谓是依托答辩，事实上现在看懂了我也不理解，我写简单点意思是一样的，有意见别找我。
5. 原先学长的PSO里面的记录数据的代码写的太乱太复杂，而且我认为没有必要记录这么多东西，或者说不符合我的习惯，怎么去记录实在是很难统一规制，大家还是怎么方便怎么来罢

6. PSO原来里面的记录record和约束constraint都是写了个空壳子，没用的。我也懒得加（优质回答），所以你在PBO和SADEA中不会看到这两个东西。有需要研究约束的话自己去找方法加进去。
7. PBO中关键的q数组中 q[0][1][2] 分别表示每次迭代基于 EI、LCB、PI 选点个数。 q=[1,0,0]既是最简单的EI贝叶斯优化，但我更推荐LCB,它易于辅助寻优。
8. LHS是拉丁超立方采样，一个初始化采样方式，具体见百度。

9. 两种辅助优化用到的代理模型最好自己定义一个库进行引用，因为还需要包括一些**预处理**和调整的操作，分开来可以使得条理清晰一些。
10. 其中高斯过程有sklearn和GPython两个库的选择，前者更易学，后者运算速度更快。
11. 新的想法和改动最好先进行**数学测试**，省时间：math_costfunc.py
数学基准测试函数介绍网站： https://www.sfu.ca/~ssurjano/index.html。
其中第三个测试函数DixonPrice是一个测试跳出鞍点的函数，建议在小维度下设置。
几乎所有资料都是错的，DixonPrice并不是单峰函数，这能很轻易证明。如果您有异议并证实你正确，本人愿意组会表演钻桌底。
12. **辅助优化的想法和对概率函数的处理**值得参考。
13. 辅助优化的方法 AuxiOpti 建议用 CMAES（研究了好几个星期）。

14. SADEA基本上是按照论文搭建的。由于DE的超参数较多，论文中也有讨论。我只做了一个改动，就是原文中 初始种群数量=建模粒子数量tau，这一定程度上限制了算法的灵活度。所以我将 **初始种群数量单独设置** ，当已计算的例子不足tau时仍能建模，超过tau后依然照论文方式。
15. python+cst 的操作见库中另一文件夹。
16. 更具体的见注释。
17. 我写的也肯定有错，欢迎大家批评指正。


白昊天
2023/09/12
